{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('C:\\\\Users\\\\Divya\\\\Google Drive\\\\Acads\\\\Courses-Winter2018\\\\CSE253-NeuralNetworks\\\\neuralnets253\\\\HW1')\n",
    "mndata.gz = True\n",
    "images, labels = mndata.load_training() #Images is a list of 60k images of 784 dimensions, Labels is a list of 60k ints\n",
    "testImages, testLabels = mndata.load_testing() #testImages is a list of 10k images of 784 dimensions, testLabels is a list of 10k ints\n",
    "testImages = np.array(testImages)\n",
    "testLabels = np.array(testLabels)\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "images = np.insert(images, 0, 1, axis=1)\n",
    "testImages = np.insert(testImages, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainImages = []\n",
    "trainLabels = []\n",
    "validImages = []\n",
    "validLabels = []\n",
    "testImgs = []\n",
    "testLbls = []\n",
    "repeatLabels = []\n",
    "cost = 0.0\n",
    "def initialize():\n",
    "    global trainImages, trainLabels, validImages, validLabels, testImgs, testLbls, repeatLabels\n",
    "    trainImages = (1/255)*images[:18000]\n",
    "    trainLabels = labels[:18000]\n",
    "    validImages = (1/255)*images[18000:20000]\n",
    "    validLabels = labels[18000:20000]\n",
    "    testImgs = (1/255)*testImages[-2000:]\n",
    "    testLbls = testLabels[-2000:]\n",
    "    #repeatLabels = np.tile(np.array([trainLabels,]).transpose(), (1, 10))\n",
    "    repeatLabels = np.zeros((len(trainImages), 10))\n",
    "    for i in range(len(trainLabels)):\n",
    "        repeatLabels[i][trainLabels[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n"
     ]
    }
   ],
   "source": [
    "initialize()\n",
    "labelNums = len(set(trainLabels)) #total number of labels\n",
    "dimensions = len(trainImages[0])\n",
    "numSamples = len(trainImages)\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weightVector = np.zeros((labelNums, dimensions))\n",
    "predictions = []\n",
    "l1Lambda = 0\n",
    "l2Lambda = 0\n",
    "learningRate = 0.0001\n",
    "\n",
    "def initializeWeight(l1, l2, lR):\n",
    "    weightVector = np.zeros((labelNums, dimensions))\n",
    "    predictions = []\n",
    "    l1Lambda = l1\n",
    "    l2Lambda = l2\n",
    "    learningRate = lR\n",
    "\n",
    "def updateLambdas(l1Lam, l2Lam):\n",
    "    global l1Lambda, l2Lambda\n",
    "    l1Lambda = l1Lam\n",
    "    l2Lambda = l2Lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(inputImages):\n",
    "    global weightVector\n",
    "    preds = np.matmul(inputImages, np.transpose(weightVector)) # n X 10\n",
    "    preds = np.exp(preds)\n",
    "    sumPred = np.sum(preds, axis=1)\n",
    "    preds = preds/sumPred[:,None]\n",
    "    return preds\n",
    "\n",
    "def accuracy(inputImages, inputLabels):\n",
    "    preds = predict(inputImages)\n",
    "    predLabels = np.argmax(preds, axis=1)\n",
    "    return accuracy_score(inputLabels, predLabels)\n",
    "\n",
    "def fin_accuracy(inputImages, inputLabels, wtVector):\n",
    "    global weightVector\n",
    "    weightVector = wtVector\n",
    "    preds = predict(inputImages)\n",
    "    predLabels = np.argmax(preds, axis=1)\n",
    "    return accuracy_score(inputLabels, predLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "l1RegAdd = l1Lambda*(np.where(weightVector>0, 1, -1))\n",
    "print(l1RegAdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateWeight(l1, preds):\n",
    "    global weightVector, l1Lambda, l2Lambda, learningRate, predictions, trainImages\n",
    "    preds = predict(trainImages)\n",
    "    predDiff = np.transpose(repeatLabels - preds);\n",
    "    if(not l1):\n",
    "        weightVector = weightVector + learningRate*((np.matmul(predDiff, trainImages)) - 2*l2Lambda*weightVector);\n",
    "    else:\n",
    "        l1RegAdd = l1Lambda*(np.where(weightVector>0, 1, -1))\n",
    "        weightVector = weightVector + (1/numSamples)*learningRate*((np.matmul(predDiff, trainImages)) - l1RegAdd);\n",
    "        \n",
    "def lossFunction(inputImages, inputLabels, preds):\n",
    "    cost = 0.0\n",
    "    for i in range(len(inputLabels)):\n",
    "        cost += (math.log(preds[i][inputLabels[i]]))\n",
    "    cost = -1*cost;\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22444.821885284062\n",
      "0.667944444444\n",
      "----------------\n",
      "2474.6341779605805\n",
      "0.687\n",
      "------------------\n",
      "45169.75048182538\n",
      "0.493833333333\n",
      "----------------\n",
      "4992.057994772885\n",
      "0.5\n",
      "------------------\n",
      "67329.24422506396\n",
      "0.484055555556\n",
      "----------------\n",
      "7934.86430271396\n",
      "0.491\n",
      "------------------\n",
      "89107.99896017426\n",
      "0.412611111111\n",
      "----------------\n",
      "10115.599425006107\n",
      "0.4145\n",
      "------------------\n",
      "91387.37659613728\n",
      "0.469555555556\n",
      "----------------\n",
      "10223.878450930557\n",
      "0.4785\n",
      "------------------\n",
      "81400.29626158108\n",
      "0.423277777778\n",
      "----------------\n",
      "9211.441022477056\n",
      "0.4435\n",
      "------------------\n",
      "64791.46802068699\n",
      "0.574055555556\n",
      "----------------\n",
      "7324.231058057572\n",
      "0.55\n",
      "------------------\n",
      "29691.85153895404\n",
      "0.608333333333\n",
      "----------------\n",
      "2927.808571885454\n",
      "0.634\n",
      "------------------\n",
      "24750.69859173095\n",
      "0.674111111111\n",
      "----------------\n",
      "2762.9971714529534\n",
      "0.684\n",
      "------------------\n",
      "27337.127961525683\n",
      "0.718\n",
      "----------------\n",
      "2960.6899553147673\n",
      "0.7315\n",
      "------------------\n",
      "26485.792605917417\n",
      "0.755888888889\n",
      "----------------\n",
      "2896.6146056271295\n",
      "0.766\n",
      "------------------\n",
      "17080.92172728809\n",
      "0.736277777778\n",
      "----------------\n",
      "1924.6961274235346\n",
      "0.745\n",
      "------------------\n",
      "17692.67481114059\n",
      "0.770555555556\n",
      "----------------\n",
      "1798.9079731997679\n",
      "0.791\n",
      "------------------\n",
      "16182.479822697918\n",
      "0.783666666667\n",
      "----------------\n",
      "1860.8061336753108\n",
      "0.785\n",
      "------------------\n",
      "12442.960462761113\n",
      "0.795222222222\n",
      "----------------\n",
      "1223.7770201452977\n",
      "0.8205\n",
      "------------------\n",
      "16041.532818233763\n",
      "0.7585\n",
      "----------------\n",
      "1742.8775580787526\n",
      "0.7565\n",
      "------------------\n",
      "17787.408266324193\n",
      "0.7215\n",
      "----------------\n",
      "1794.8471379724892\n",
      "0.743\n",
      "------------------\n",
      "24709.226350646513\n",
      "0.741944444444\n",
      "----------------\n",
      "2769.880902403238\n",
      "0.7385\n",
      "------------------\n",
      "13382.883899876877\n",
      "0.791333333333\n",
      "----------------\n",
      "1332.021119226137\n",
      "0.8105\n",
      "------------------\n",
      "12573.711630977665\n",
      "0.804944444444\n",
      "----------------\n",
      "1414.602822573901\n",
      "0.8065\n",
      "------------------\n",
      "12738.720992850665\n",
      "0.810722222222\n",
      "----------------\n",
      "1270.538865040197\n",
      "0.828\n",
      "------------------\n",
      "11199.84864325571\n",
      "0.813055555556\n",
      "----------------\n",
      "1189.0705715393358\n",
      "0.8195\n",
      "------------------\n",
      "12400.754947735044\n",
      "0.796111111111\n",
      "----------------\n",
      "1226.3023210015508\n",
      "0.815\n",
      "------------------\n",
      "14684.286130429395\n",
      "0.784666666667\n",
      "----------------\n",
      "1576.290184633986\n",
      "0.789\n",
      "------------------\n",
      "12332.530822725284\n",
      "0.794055555556\n",
      "----------------\n",
      "1215.4155167448582\n",
      "0.817\n",
      "------------------\n",
      "14201.399486312954\n",
      "0.792888888889\n",
      "----------------\n",
      "1516.9933613006094\n",
      "0.7985\n",
      "------------------\n",
      "11182.271920575758\n",
      "0.813\n",
      "----------------\n",
      "1102.7972808851355\n",
      "0.8365\n",
      "------------------\n",
      "11654.01300503679\n",
      "0.813055555556\n",
      "----------------\n",
      "1227.9129062752122\n",
      "0.8205\n",
      "------------------\n",
      "10492.931245870346\n",
      "0.824277777778\n",
      "----------------\n",
      "1034.1170368608732\n",
      "0.8465\n",
      "------------------\n",
      "10651.941153920707\n",
      "0.826444444444\n",
      "----------------\n",
      "1119.1092641993855\n",
      "0.8335\n",
      "------------------\n",
      "9799.377068251419\n",
      "0.835944444444\n",
      "----------------\n",
      "963.4207524338683\n",
      "0.8595\n",
      "------------------\n",
      "9594.808542153918\n",
      "0.845277777778\n",
      "----------------\n",
      "1006.0047784012716\n",
      "0.852\n",
      "------------------\n",
      "9032.419644626332\n",
      "0.848333333333\n",
      "----------------\n",
      "886.2988108026545\n",
      "0.8695\n",
      "------------------\n",
      "8679.78681957819\n",
      "0.859611111111\n",
      "----------------\n",
      "910.0454820816066\n",
      "0.865\n",
      "------------------\n",
      "8360.193936122683\n",
      "0.859777777778\n",
      "----------------\n",
      "819.7443723652739\n",
      "0.885\n",
      "------------------\n",
      "8062.938352275179\n",
      "0.869388888889\n",
      "----------------\n",
      "846.6339207564462\n",
      "0.8775\n",
      "------------------\n",
      "7904.1577685147995\n",
      "0.868722222222\n",
      "----------------\n",
      "775.7250504784759\n",
      "0.891\n",
      "------------------\n",
      "7707.033837965392\n",
      "0.874055555556\n",
      "----------------\n",
      "810.3477327598918\n",
      "0.882\n",
      "------------------\n",
      "7621.373856456671\n",
      "0.872555555556\n",
      "----------------\n",
      "749.0155929516176\n",
      "0.8955\n",
      "------------------\n",
      "7491.783679101147\n",
      "0.877444444444\n",
      "----------------\n",
      "788.2912454168776\n",
      "0.887\n",
      "------------------\n",
      "7440.869755475438\n",
      "0.876333333333\n",
      "----------------\n",
      "732.2130135226132\n",
      "0.899\n",
      "------------------\n",
      "7350.192501341744\n",
      "0.880166666667\n",
      "----------------\n",
      "774.012943560309\n",
      "0.8895\n",
      "------------------\n",
      "7327.403192162797\n",
      "0.878722222222\n",
      "----------------\n",
      "721.7957211448079\n",
      "0.9005\n",
      "------------------\n",
      "7259.473557499925\n",
      "0.881611111111\n",
      "----------------\n",
      "765.5729891589652\n",
      "0.8895\n",
      "------------------\n",
      "7269.284515391708\n",
      "0.879\n",
      "----------------\n",
      "716.6542507768274\n",
      "0.9005\n",
      "------------------\n",
      "7214.058245051776\n",
      "0.882333333333\n",
      "----------------\n",
      "762.6081541080467\n",
      "0.8895\n",
      "------------------\n",
      "7265.975514816797\n",
      "0.878444444444\n",
      "----------------\n",
      "716.8101189812659\n",
      "0.8995\n",
      "------------------\n",
      "7215.028548581556\n",
      "0.882722222222\n",
      "----------------\n",
      "765.3436682899663\n",
      "0.8895\n",
      "------------------\n",
      "7323.547011271575\n",
      "0.877722222222\n",
      "----------------\n",
      "722.9792637962329\n",
      "0.898\n",
      "------------------\n",
      "7266.699595934738\n",
      "0.881555555556\n",
      "----------------\n",
      "774.2844717270627\n",
      "0.889\n",
      "------------------\n",
      "7452.516942992621\n",
      "0.875333333333\n",
      "----------------\n",
      "736.3939613812327\n",
      "0.896\n",
      "------------------\n",
      "7374.022623159841\n",
      "0.879833333333\n",
      "----------------\n",
      "789.8928320398393\n",
      "0.8875\n",
      "------------------\n",
      "7663.720323965324\n",
      "0.872\n",
      "----------------\n",
      "758.424440173271\n",
      "0.89\n",
      "------------------\n",
      "7537.719514385449\n",
      "0.876722222222\n",
      "----------------\n",
      "811.9086297077971\n",
      "0.881\n",
      "------------------\n",
      "7957.318101667315\n",
      "0.867722222222\n",
      "----------------\n",
      "789.4366592300582\n",
      "0.886\n",
      "------------------\n",
      "7746.704674669173\n",
      "0.872\n",
      "----------------\n",
      "838.2952819926044\n",
      "0.8775\n",
      "------------------\n",
      "8302.790212375066\n",
      "0.862111111111\n",
      "----------------\n",
      "826.5461068521992\n",
      "0.882\n",
      "------------------\n",
      "7977.168334690301\n",
      "0.866111111111\n",
      "----------------\n",
      "865.1331338282498\n",
      "0.873\n",
      "------------------\n",
      "8630.931318386256\n",
      "0.857277777778\n",
      "----------------\n",
      "862.4612955335059\n",
      "0.881\n",
      "------------------\n",
      "8220.545595515177\n",
      "0.861722222222\n",
      "----------------\n",
      "890.4622878108518\n",
      "0.868\n",
      "------------------\n",
      "8888.868010340087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-242-34d02a3b736a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpredis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlossFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"----------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpredis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-239-dff72c5601ca>\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(inputImages, inputLabels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpredLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputLabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredLabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-239-dff72c5601ca>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(inputImages)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mweightVector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweightVector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# n X 10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msumPred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#minError = sys.maxsize\n",
    "predis = predict(trainImages)\n",
    "for i in range(100):\n",
    "    predis = predict(trainImages)\n",
    "    updateWeight(False, predis)\n",
    "    predis = predict(trainImages)\n",
    "    print(lossFunction(trainImages, trainLabels, predis))\n",
    "    print(accuracy(trainImages, trainLabels))\n",
    "    print(\"----------------\")\n",
    "    predis = predict(validImages)\n",
    "    print(lossFunction(validImages, validLabels, predis))\n",
    "    print(accuracy(validImages, validLabels))\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "minErrorWts = []\n",
    "def gradDescent(lamdas, l1reg, learningRate):\n",
    "    for lam in lamdas:\n",
    "        print(\"For lamda: \", lam)\n",
    "        initializeWeight(lam, lam, learningRate)\n",
    "        minErrorOnValid = sys.maxsize\n",
    "        prevValErr = sys.maxsize\n",
    "        epochsOvershoot = 0\n",
    "        i = 0\n",
    "        iters = []\n",
    "        trainError = []\n",
    "        trainAccuracy = []\n",
    "        validError = []\n",
    "        validAccuracy = []\n",
    "        testError = []\n",
    "        testAccuracy = []\n",
    "        minErrWeights = []\n",
    "        minWeightIter = 0\n",
    "        while(True):\n",
    "            i += 1\n",
    "            iters.append(i)\n",
    "            #print(trainImages.shape)\n",
    "            predic = predict(trainImages)\n",
    "            updateWeight(l1reg, predic)\n",
    "            \n",
    "            trErr = lossFunction(trainImages, trainLabels, predict(trainImages))\n",
    "            trainError.append(trErr)\n",
    "            trAcc = accuracy(trainImages, trainLabels)\n",
    "            trainAccuracy.append(trAcc)\n",
    "            \n",
    "            valErr = lossFunction(validImages, validLabels, predict(validImages))\n",
    "            validError.append(valErr)\n",
    "            valAcc = accuracy(validImages, validLabels)\n",
    "            validAccuracy.append(valAcc)\n",
    "            \n",
    "            testErr = lossFunction(testImgs, testLbls, predict(testImgs))\n",
    "            testError.append(testErr)\n",
    "            testAcc = accuracy(testImgs, testLbls)\n",
    "            testAccuracy.append(testAcc)\n",
    "            \n",
    "            if(valErr<minErrorOnValid):\n",
    "                minErrorOnValid = valErr\n",
    "                minErrWeights = weightVector\n",
    "                minWeightIter = i\n",
    "                \n",
    "            if(valErr<prevValErr):\n",
    "                epochsOvershoot += 1\n",
    "                if(epochsOvershoot>=4):\n",
    "                    break\n",
    "            else:\n",
    "                epochsOvershoot = 0\n",
    "                \n",
    "            prevValErr = valErr\n",
    "        \n",
    "        minErrorWts.append(minErrWeights)\n",
    "        print(\"Train accuracy at min err weights: \", fin_accuracy(trainImages, trainLabels, minErrWeights))\n",
    "        print(\"Valid accuracy at min err weights: \", fin_accuracy(validImages, validLabels, minErrWeights))\n",
    "        print(\"Test accuracy at min err weights: \", fin_accuracy(testImgs, testLbls, minErrWeights))\n",
    "            \n",
    "        plt.figure(1)\n",
    "        plt.subplot(211)\n",
    "        plt.plot(trainError, label='Train', color='blue')\n",
    "        plt.plot(validError, label='Validation', color='red')\n",
    "        plt.plot(testError, label='Test', color='green')\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        \n",
    "        plt.subplot(212)\n",
    "        plt.plot(trainAccuracy, label='Train', color='blue')\n",
    "        plt.plot(validAccuracy, label='Validation', color='red')\n",
    "        plt.plot(testAccuracy, label='Test', color='green')\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lamda:  0.001\n",
      "Train accuracy at min err weights:  0.668055555556\n",
      "Valid accuracy at min err weights:  0.687\n",
      "Test accuracy at min err weights:  0.6865\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2510b274160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For lamda:  0.0001\n",
      "Train accuracy at min err weights:  0.668333333333\n",
      "Valid accuracy at min err weights:  0.687\n",
      "Test accuracy at min err weights:  0.687\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2510b28d2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gradDescent([0.001, 0.0001], True, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
