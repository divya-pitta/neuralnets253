{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "\n",
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "mndata = MNIST(\"/Users/jigyayadav/Desktop/Codes/neuralnets253/HW1\")\n",
    "mndata.gz = True\n",
    "images, labels = mndata.load_training() #Images is a list of 60000 images of 784 dimensions, Labels is a list of 60000 ints\n",
    "imagesTest, labelsTest = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "imagesTest = np.array(imagesTest)\n",
    "labelsTest = np.array(labelsTest)\n",
    "\n",
    "images_train = images[:20000]\n",
    "images_test = imagesTest[-2000:]\n",
    "labels_train = labels[:20000]\n",
    "labels_test = labelsTest[-2000:]\n",
    "images_train = np.array(images_train)\n",
    "labels_train = np.array(labels_train)\n",
    "images_test = np.array(images_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "# Normalization\n",
    "images_train = images_train*(1/127.5)\n",
    "images_test = images_test*(1/127.5)\n",
    "images_train = images_train-1.0\n",
    "images_test = images_test-1.0\n",
    "\n",
    "# Should this be appended after or before normalization\n",
    "images_train = np.insert(images_train, 0, 1, axis=1)\n",
    "images_test = np.insert(images_test, 0, 1, axis=1)\n",
    "\n",
    "numFeatures = len(images[0, :])\n",
    "\n",
    "# Divide between validation and training\n",
    "from sklearn.model_selection import train_test_split\n",
    "images_train, images_validation, labels_train, labels_validation = train_test_split(images_train, labels_train, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelNums = 10\n",
    "\n",
    "def labelsToVectForm(labels):\n",
    "    vectForm = np.zeros((len(labels), labelNums))\n",
    "    for i in range(len(labels)):\n",
    "        vectForm[i][labels[i]] = 1\n",
    "    return vectForm\n",
    "\n",
    "t_train = labelsToVectForm(labels_train)\n",
    "t_test = labelsToVectForm(labels_test)\n",
    "t_validation = labelsToVectForm(labels_validation)\n",
    "\n",
    "x = images_train\n",
    "t = t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 785)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current training error =  104576.8276189047\n",
      "Current validation error =  11919.484318599905\n",
      "Current training accuracy =  0.12033333333333333\n",
      "Current validation accuracy =  0.12\n",
      "Current training error =  88993.68009976037\n",
      "Current validation error =  10165.253204233999\n",
      "Current training accuracy =  0.18\n",
      "Current validation accuracy =  0.1755\n",
      "Current training error =  82035.54828948776\n",
      "Current validation error =  9137.416381025134\n",
      "Current training accuracy =  0.1947222222222222\n",
      "Current validation accuracy =  0.2015\n",
      "Current training error =  80396.71899177802\n",
      "Current validation error =  8936.146426310566\n",
      "Current training accuracy =  0.19944444444444445\n",
      "Current validation accuracy =  0.192\n",
      "Current training error =  73686.56286687643\n",
      "Current validation error =  8027.648875656128\n",
      "Current training accuracy =  0.22022222222222224\n",
      "Current validation accuracy =  0.2255\n",
      "Current training error =  84115.61898511862\n",
      "Current validation error =  9363.46494418695\n",
      "Current training accuracy =  0.20844444444444443\n",
      "Current validation accuracy =  0.205\n",
      "Current training error =  68273.73514885566\n",
      "Current validation error =  7408.145195338291\n",
      "Current training accuracy =  0.18738888888888888\n",
      "Current validation accuracy =  0.1935\n",
      "Current training error =  60230.67560312561\n",
      "Current validation error =  6597.582030900958\n",
      "Current training accuracy =  0.3367222222222222\n",
      "Current validation accuracy =  0.347\n",
      "Current training error =  49135.04796508714\n",
      "Current validation error =  5510.960978905738\n",
      "Current training accuracy =  0.30666666666666664\n",
      "Current validation accuracy =  0.304\n",
      "Current training error =  43252.50110448723\n",
      "Current validation error =  4793.293778038195\n",
      "Current training accuracy =  0.3234444444444444\n",
      "Current validation accuracy =  0.3215\n",
      "Current training error =  44310.207873206135\n",
      "Current validation error =  4954.752550336642\n",
      "Current training accuracy =  0.30444444444444446\n",
      "Current validation accuracy =  0.299\n",
      "Current training error =  42746.184359124476\n",
      "Current validation error =  4817.079353851663\n",
      "Current training accuracy =  0.372\n",
      "Current validation accuracy =  0.361\n",
      "Current training error =  33565.53162230976\n",
      "Current validation error =  3715.994553072515\n",
      "Current training accuracy =  0.37522222222222223\n",
      "Current validation accuracy =  0.3895\n",
      "Current training error =  36983.67687079206\n",
      "Current validation error =  4289.35469759793\n",
      "Current training accuracy =  0.4856666666666667\n",
      "Current validation accuracy =  0.4815\n",
      "Current training error =  25168.782211653597\n",
      "Current validation error =  2816.7873636328322\n",
      "Current training accuracy =  0.5333888888888889\n",
      "Current validation accuracy =  0.532\n",
      "Current training error =  25806.630689208963\n",
      "Current validation error =  2881.8934714831757\n",
      "Current training accuracy =  0.5192777777777777\n",
      "Current validation accuracy =  0.5345\n",
      "Current training error =  25594.774713760256\n",
      "Current validation error =  2830.519201396244\n",
      "Current training accuracy =  0.5323888888888889\n",
      "Current validation accuracy =  0.5405\n",
      "Current training error =  27508.666510455518\n",
      "Current validation error =  3035.8690437409614\n",
      "Current training accuracy =  0.5222222222222223\n",
      "Current validation accuracy =  0.5295\n",
      "Current training error =  24133.155239027867\n",
      "Current validation error =  2672.3197042766205\n",
      "Current training accuracy =  0.5633888888888889\n",
      "Current validation accuracy =  0.5695\n",
      "Current training error =  22952.843619052313\n",
      "Current validation error =  2540.6515397461226\n",
      "Current training accuracy =  0.5636111111111111\n",
      "Current validation accuracy =  0.5755\n",
      "Current training error =  24601.336235483774\n",
      "Current validation error =  2739.7123127656464\n",
      "Current training accuracy =  0.5673333333333334\n",
      "Current validation accuracy =  0.582\n",
      "Current training error =  22811.291436617183\n",
      "Current validation error =  2526.1059917074426\n",
      "Current training accuracy =  0.5687222222222222\n",
      "Current validation accuracy =  0.5755\n",
      "Current training error =  23710.343941135267\n",
      "Current validation error =  2644.6058081169244\n",
      "Current training accuracy =  0.5625555555555556\n",
      "Current validation accuracy =  0.578\n",
      "Current training error =  23502.92831225278\n",
      "Current validation error =  2604.8974311177967\n",
      "Current training accuracy =  0.568\n",
      "Current validation accuracy =  0.575\n",
      "Current training error =  23038.261466686836\n",
      "Current validation error =  2589.89200023632\n",
      "Current training accuracy =  0.5846111111111111\n",
      "Current validation accuracy =  0.5935\n",
      "Current training error =  21992.56778259598\n",
      "Current validation error =  2440.664107012375\n",
      "Current training accuracy =  0.586\n",
      "Current validation accuracy =  0.5835\n",
      "Current training error =  22457.764380394598\n",
      "Current validation error =  2521.1238766364413\n",
      "Current training accuracy =  0.5965\n",
      "Current validation accuracy =  0.6055\n",
      "Current training error =  20732.781814756196\n",
      "Current validation error =  2316.298190513028\n",
      "Current training accuracy =  0.5996666666666667\n",
      "Current validation accuracy =  0.6065\n",
      "Current training error =  20782.729512929465\n",
      "Current validation error =  2335.5753753961067\n",
      "Current training accuracy =  0.6273888888888889\n",
      "Current validation accuracy =  0.6455\n",
      "Current training error =  20220.312738893146\n",
      "Current validation error =  2269.8314909708865\n",
      "Current training accuracy =  0.6156111111111111\n",
      "Current validation accuracy =  0.609\n",
      "Current training error =  18420.71275785144\n",
      "Current validation error =  2059.285252955262\n",
      "Current training accuracy =  0.6461666666666667\n",
      "Current validation accuracy =  0.666\n",
      "Current training error =  18918.7758375221\n",
      "Current validation error =  2125.3000714089635\n",
      "Current training accuracy =  0.6318888888888889\n",
      "Current validation accuracy =  0.63\n",
      "Current training error =  17922.00344538375\n",
      "Current validation error =  2022.9715044842915\n",
      "Current training accuracy =  0.6613888888888889\n",
      "Current validation accuracy =  0.668\n",
      "Current training error =  17742.35599674945\n",
      "Current validation error =  1995.0867845760783\n",
      "Current training accuracy =  0.6575\n",
      "Current validation accuracy =  0.659\n",
      "Current training error =  17316.47055425983\n",
      "Current validation error =  1968.6441500005699\n",
      "Current training accuracy =  0.6682777777777777\n",
      "Current validation accuracy =  0.669\n",
      "Current training error =  17325.27258444852\n",
      "Current validation error =  1944.3390646680318\n",
      "Current training accuracy =  0.6675\n",
      "Current validation accuracy =  0.669\n",
      "Current training error =  17146.86526644085\n",
      "Current validation error =  1959.2108725954345\n",
      "Current training accuracy =  0.6709444444444445\n",
      "Current validation accuracy =  0.663\n",
      "Current training error =  17565.441314328764\n",
      "Current validation error =  1963.0423124859856\n",
      "Current training accuracy =  0.6625\n",
      "Current validation accuracy =  0.6645\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-89f93288107b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0msummation_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2_nobias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mg_derivative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mdelE_Wij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummation_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_derivative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mdelE_Wij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelE_Wij\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "\n",
    "# Forward propagation\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmaxFunc(prod):\n",
    "    prod = np.exp(prod)\n",
    "    for i in range(len(prod)):\n",
    "        rowSum = sum(prod[i, :])\n",
    "        for j in range(len(prod[i, :])):\n",
    "            prod[i][j] = prod[i][j]/rowSum    \n",
    "    return prod\n",
    "\n",
    "def getPredClass(y):\n",
    "    predClass = np.argmax(y, axis=1)\n",
    "    return predClass\n",
    "\n",
    "def calculateOutput(x, W1, W2):\n",
    "    A1 = x.dot(W1)\n",
    "    Z1 = sigmoid(A1)\n",
    "    X2 = np.insert(Z1, 0, 1, axis=1)\n",
    "    A2 = X2.dot(W2)\n",
    "    Y = softmaxFunc(A2)\n",
    "    return Y\n",
    "\n",
    "def calculateCost(x, t, W1, W2):\n",
    "    sampLen = len(x)\n",
    "    Y = calculateOutput(x, W1, W2)\n",
    "    cost = -1*(np.sum(np.multiply(t, np.log(Y))))\n",
    "    return cost\n",
    "\n",
    "def calculateCostOneInstance(x, t, W1, W2, n):\n",
    "    sampLen = len(x)\n",
    "    Y = calculateOutput(x, W1, W2)\n",
    "    cost = -1*(np.multiply(t, np.log(Y)))\n",
    "    return np.sum(cost[n, :])\n",
    "\n",
    "def calculateAccuracy(x, labels, W1, W2):\n",
    "    Y = calculateOutput(x, W1, W2)\n",
    "    predClass = getPredClass(Y)\n",
    "    return accuracy_score(labels, predClass)\n",
    "\n",
    "\n",
    "W1 = np.random.uniform(low=-1.0, high=1.0, size=(785, 64))\n",
    "W2 = np.random.uniform(low=-1.0, high=1.0, size=(65, 10))\n",
    "epsilon = 0.001\n",
    "learningRate = 0.0001\n",
    "\n",
    "for itr in range(5000):\n",
    "    A1 = x.dot(W1)\n",
    "    Z1 = sigmoid(A1)\n",
    "\n",
    "#     print(Z1[0, :])\n",
    "    X2 = np.insert(Z1, 0, 1, axis=1)\n",
    "#     print(X2[0, :])\n",
    "#     print(\"X2 : \")\n",
    "#     print(X2)\n",
    "#     print(\"W2 : \")\n",
    "#     print(W2)\n",
    "    A2 = X2.dot(W2)\n",
    "#     print(\"A2 : \")\n",
    "#     print(A2)\n",
    "    Y = np.exp(A2)/np.sum(np.exp(A2), axis=1, keepdims = True)\n",
    "\n",
    "#     Y_p = softmaxFunc(A2)\n",
    "# #     print(\"Y-Y_p\")\n",
    "# #     print(Y-Y_p)\n",
    "\n",
    "    # Backward propagation\n",
    "    W2_nobias = np.delete(W2, (0), axis=0)\n",
    "    summation_k = (Y-t).dot(W2_nobias.T)\n",
    "    g_derivative = Z1*(1-Z1)\n",
    "    delE_Wij = x.T.dot(np.multiply(summation_k, g_derivative))\n",
    "    delE_Wij = delE_Wij\n",
    "    \n",
    "    # Check approximate derivative\n",
    "#     for n in range(0, 150, 30):\n",
    "#         print(\"For input to hidden layers\")\n",
    "#         for i in range(0, 785, 100):\n",
    "#             for j in range(0, 64, 20):\n",
    "#                 del_En_Wij = (g_derivative[n][j]*summation_k[n][j]*x[n][i])\n",
    "#                 modifiedW1 = W1\n",
    "#                 modifiedW1[i][j] += epsilon\n",
    "#                 costFunction1 = calculateCostOneInstance(x, t, modifiedW1, W2, n)\n",
    "#                 modifiedW1[i][j] -= 2*epsilon\n",
    "#                 costFunction2 = calculateCostOneInstance(x, t, modifiedW1, W2, n)\n",
    "#                 approx_delEn = (costFunction1-costFunction2)/(2*epsilon)\n",
    "#                 diff = abs(del_En_Wij-approx_delEn)\n",
    "# #                 print(del_En_Wij, \" \", approx_delEn)\n",
    "#                 if (diff > epsilon*epsilon):\n",
    "#                     print(\"Difference between approximate gradient = \", diff, \" \", abs(epsilon*epsilon-diff))\n",
    "        \n",
    "#         print(\"For hidden to output layers\")\n",
    "#         for j in range(0, 65, 20):\n",
    "#             for k in range(0, 10, 3):\n",
    "#                 actualDerivative = X2[n][j]*(Y[n][k]-t[n][k])\n",
    "#                 modifiedW2 = W2\n",
    "#                 modifiedW2[j][k] += epsilon\n",
    "#                 costFunction1 = calculateCostOneInstance(x, t, W1, modifiedW2, n)\n",
    "#                 modifiedW2[j][k] -= 2*epsilon\n",
    "#                 costFunction2 = calculateCostOneInstance(x, t, W1, modifiedW2, n)\n",
    "#                 approximateDerivative = (costFunction1-costFunction2)/(2*epsilon)\n",
    "#                 diff = abs(actualDerivative-approximateDerivative)\n",
    "# #                 print(actualDerivative, \" \", approximateDerivative)\n",
    "#                 if (diff > epsilon*epsilon):\n",
    "#                     print(\"Difference between approximate gradient = \", diff, \" \", abs(epsilon*epsilon-diff))\n",
    "                \n",
    "    W2 = W2-learningRate*((X2.T.dot(Y-t)))\n",
    "    W1 = W1-learningRate*(delE_Wij)\n",
    "    \n",
    "    # Calculate validation error\n",
    "    currTrainingError = calculateCost(x, t, W1, W2)\n",
    "    currvalidationError = calculateCost(images_validation, t_validation, W1, W2)\n",
    "    currTrainingAccuracy = calculateAccuracy(x, labels_train, W1, W2)\n",
    "    currValidationAccuracy = calculateAccuracy(images_validation, labels_validation, W1, W2)\n",
    "    print(\"Current training error = \", currTrainingError)\n",
    "    print(\"Current validation error = \", currvalidationError)\n",
    "    print(\"Current training accuracy = \", currTrainingAccuracy)\n",
    "    print(\"Current validation accuracy = \", currValidationAccuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
